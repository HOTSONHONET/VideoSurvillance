{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoSurvillance_OP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssQh3lcZhE98",
        "outputId": "ac131e6f-5591-46ec-a64a-f6ed009bdd20"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"./drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gwgHWtWoQ57"
      },
      "source": [
        "# Downloading Dataset and saving it inside Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV5fvdbIiGX-",
        "outputId": "2c20edc7-b9f5-4cb0-caac-cbdc9aed203d"
      },
      "source": [
        "# !wget http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/Avenue_Dataset.zip\n",
        "# !wget http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/ground_truth_demo.zip\n",
        "# !mkdir ./Avenue_Dataset\n",
        "# !unzip /content/Avenue_Dataset.zip -d ./Avenue_Dataset\n",
        "# !unzip ./ground_truth_demo.zip -d ./Avenue_Dataset\n",
        "# !wget http://www.svcl.ucsd.edu/projects/anomaly/UCSD_Anomaly_Dataset.tar.gz\n",
        "# !mkdir ./UCSD_Anomaly_Dataset\n",
        "# !tar -xzvf ./UCSD_Anomaly_Dataset.tar.gz -C ./UCSD_Anomaly_Dataset\n",
        "# !mkdir ./drive/MyDrive/AnormalyDetectionDataset\n",
        "# !mv ./Avenue_Dataset ./drive/MyDrive/AnormalyDetectionDataset\n",
        "# !mv ./UCSD_Anomaly_Dataset ./drive/MyDrive/AnormalyDetectionDataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-05 08:39:34--  http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/Avenue_Dataset.zip\n",
            "Resolving www.cse.cuhk.edu.hk (www.cse.cuhk.edu.hk)... 137.189.91.192\n",
            "Connecting to www.cse.cuhk.edu.hk (www.cse.cuhk.edu.hk)|137.189.91.192|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 813227845 (776M) [application/zip]\n",
            "Saving to: ‘Avenue_Dataset.zip’\n",
            "\n",
            "Avenue_Dataset.zip  100%[===================>] 775.55M  4.55MB/s    in 2m 44s  \n",
            "\n",
            "2021-03-05 08:42:18 (4.74 MB/s) - ‘Avenue_Dataset.zip’ saved [813227845/813227845]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADQ1VGTJWZhi"
      },
      "source": [
        "# Importing Data from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj_e2vzIW1BE",
        "outputId": "df698eed-f922-4a1b-b463-269d399fd44b"
      },
      "source": [
        "data_path = 'drive/myDrive/AnormalyDetectionDataset'\r\n",
        "!ls ./drive/MyDrive/AnormalyDetectionDataset/UCSD_Anomaly_Dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UCSD_Anomaly_Dataset.v1p2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfVLFtKvoVn1"
      },
      "source": [
        "# Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUN0dFslpDxL",
        "outputId": "cbdc3155-508b-47e1-abdf-db350fa8e3f6"
      },
      "source": [
        "!pip install livelossplot"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/57/26/840be243088ce142d61c60273408ec09fa1de4534056a56d6e91b73f0cae/livelossplot-0.5.4-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.1.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.19.5)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (20.9)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.0.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (54.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.7.0)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kKx--WQToMM7",
        "outputId": "5cb19389-9026-4b58-c1c2-54b65464d288"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "from tensorflow.keras.models import *\r\n",
        "from tensorflow.keras.applications import *\r\n",
        "from tensorflow.keras.preprocessing.image import *\r\n",
        "from tensorflow.keras.optimizers import *\r\n",
        "from tensorflow.keras.metrics import *\r\n",
        "\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from livelossplot import PlotLossesKeras\r\n",
        "from tensorflow.keras.callbacks import *\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "from imutils import build_montages\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "from collections import Counter\r\n",
        "import imutils\r\n",
        "from imutils import paths\r\n",
        "\r\n",
        "from scipy.spatial.distance import cosine, euclidean\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from glob import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from plotly.subplots import make_subplots\r\n",
        "import plotly.express as px\r\n",
        "import plotly.graph_objects as go\r\n",
        "import plotly as ply\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n",
        "ply.offline.init_notebook_mode(connected=True)\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VClgXPIGscA5"
      },
      "source": [
        "# Creating the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIobSTtAOeaJ"
      },
      "source": [
        "train_path = \"./drive/MyDrive/AnormalyDetectionDataset/Avenue_Dataset/Avenue Dataset/training_videos\"\r\n",
        "test_path = \"./drive/MyDrive/AnormalyDetectionDataset/Avenue_Dataset/Avenue Dataset/testing_videos\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO0T0FUxpHb-"
      },
      "source": [
        "store_imgs = []\r\n",
        "fps = 5\r\n",
        "train_videos = os.listdir(train_path)\r\n",
        "train_images_path = train_path + '/frames'\r\n",
        "os.makedirs(train_images_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4qGACX0PVs5"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPOzxhvjNGpo"
      },
      "source": [
        "# To collect frames from videos and make a dataset out of it\r\n",
        "def store_in_array(image_path):\r\n",
        "    image = load_img(image_path)\r\n",
        "    image = img_to_array(image)\r\n",
        "    image = cv2.resize(\r\n",
        "        image, \r\n",
        "        (227, 227),\r\n",
        "        interpolation = cv2.INTER_AREA\r\n",
        "        )\r\n",
        "    gray = 0.2989*image[:,:,0]+0.5870*image[:,:,1]+0.1140*image[:,:,2]\r\n",
        "    store_imgs.append(gray)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdIYb3DlSYD4",
        "outputId": "ec892777-0b79-480e-87d6-bb1db8bcd97d"
      },
      "source": [
        "train_videos"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['01.avi',\n",
              " '02.avi',\n",
              " '03.avi',\n",
              " '04.avi',\n",
              " '05.avi',\n",
              " '06.avi',\n",
              " '07.avi',\n",
              " '08.avi',\n",
              " '09.avi',\n",
              " '10.avi',\n",
              " '11.avi',\n",
              " '12.avi',\n",
              " '14.avi',\n",
              " '13.avi',\n",
              " '15.avi',\n",
              " '16.avi',\n",
              " 'frames']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PXejdexVh5d",
        "outputId": "188637d2-8a3d-4f13-c83e-31d3ef49a7ea"
      },
      "source": [
        "!apt install ffmpeg"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV3WulCYQHZ6",
        "outputId": "ca0ec89d-83fa-40b6-ae45-1420bc66abbe"
      },
      "source": [
        "for video in tqdm(train_videos):\r\n",
        "    os.system('ffmpeg -i \"{}/{}\" -r 1/{}  \"{}/frames/%03d.jpg\"'.format(train_path,video,fps,train_path))\r\n",
        "    images=os.listdir(train_images_path)\r\n",
        "    for image in images:\r\n",
        "        image_path=train_images_path + '/' + image\r\n",
        "        store_in_array(image_path)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17/17 [00:30<00:00,  1.77s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74KKPZGbQrhZ"
      },
      "source": [
        "store_imgs = np.array(store_imgs)\r\n",
        "a, b, c = store_imgs.shape\r\n",
        "\r\n",
        "store_imgs.resize(b, c, a)\r\n",
        "store_imgs = (store_imgs-store_imgs.mean())/(store_imgs.std())\r\n",
        "store_imgs = np.clip(store_imgs, 0, 1)\r\n",
        "np.save(f'./drive/MyDrive/AnormalyDetectionDataset/training.npy', store_imgs)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRwMJiXyZXCt"
      },
      "source": [
        "# Building Spatio-Temporal AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1sSgmHoQ0Bs"
      },
      "source": [
        "class ST_Autoencoder:\r\n",
        "        \r\n",
        "    def __init__(self, input_dim, z_dim):         \r\n",
        "        self.input_dim = input_dim\r\n",
        "        self.z_dim = z_dim\r\n",
        "        print(\"[INFO] Build your model by calling build()..\")\r\n",
        "\r\n",
        "    def build(self):\r\n",
        "        # Encoder\r\n",
        "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\r\n",
        "\r\n",
        "        enc_x = encoder_input\r\n",
        "        enc_x = Conv3D(filters = 128,\r\n",
        "                   kernel_size = (11, 11, 1),\r\n",
        "                   strides = (4, 4, 1),\r\n",
        "                   padding = 'valid',\r\n",
        "                   kernel_initializer = 'he_uniform',\r\n",
        "                   activation = 'relu'\r\n",
        "                   )(enc_x)\r\n",
        "        enc_x = Conv3D(filters = 64,\r\n",
        "                   kernel_size = (5, 5, 1),\r\n",
        "                   strides = (2, 2, 1),\r\n",
        "                   padding = 'valid',\r\n",
        "                   kernel_initializer = 'he_uniform',\r\n",
        "                   activation = 'relu'\r\n",
        "                   )(enc_x)\r\n",
        "        enc_x = ConvLSTM2D(filters=64,\r\n",
        "                       kernel_size=(3,3),\r\n",
        "                       strides=1,\r\n",
        "                       padding='same',\r\n",
        "                       dropout=0.4,\r\n",
        "                       recurrent_dropout=0.3,\r\n",
        "                       return_sequences=True\r\n",
        "                    )(enc_x)\r\n",
        "        embedding = ConvLSTM2D(filters=self.z_dim,\r\n",
        "                       kernel_size=(3,3),\r\n",
        "                       strides=1,\r\n",
        "                       padding='same',\r\n",
        "                       dropout=0.3,                       \r\n",
        "                       return_sequences=True\r\n",
        "                    )(enc_x)\r\n",
        "\r\n",
        "        # Decoder\r\n",
        "        dec_x = ConvLSTM2D(filters=64,\r\n",
        "                           kernel_size=(3,3),\r\n",
        "                           strides=1,\r\n",
        "                           return_sequences=True, \r\n",
        "                           padding='same',\r\n",
        "                           dropout=0.5\r\n",
        "                        )(embedding)\r\n",
        "        dec_x = Conv3DTranspose(filters=128,\r\n",
        "                                kernel_size=(5,5,1),\r\n",
        "                                strides=(2,2,1),\r\n",
        "                                padding='valid',\r\n",
        "                                activation='relu'\r\n",
        "                            )(dec_x)\r\n",
        "        decoder_output = Conv3DTranspose(filters=1,\r\n",
        "                                kernel_size=(11,11,1),\r\n",
        "                                strides=(4, 4, 1),\r\n",
        "                                padding='valid',\r\n",
        "                                activation='relu'\r\n",
        "                            )(dec_x)       \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        stae = Model(inputs=encoder_input, outputs=decoder_output, name=\"Spatio-Temporal-AutoEncoder\")\r\n",
        "        stae.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\r\n",
        "        print()\r\n",
        "        print(\"=======================================\")\r\n",
        "        print(\"[INFO] Model compilation Done..\")\r\n",
        "        print(\"=======================================\")\r\n",
        "        print()\r\n",
        "        print(stae.summary())\r\n",
        "        return stae\r\n",
        "\r\n",
        "    \r\n",
        "    def __str__():\r\n",
        "        return \"Spatio-Temporal-AutoEncoder\""
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWUOMKRzcNGM",
        "outputId": "29ecb7c2-ca8c-4695-ffef-19f657c17ab8"
      },
      "source": [
        "modelBuilder = ST_Autoencoder(input_dim=(227, 227, 10, 1),\r\n",
        "                              z_dim = 32)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Build your model by calling build()..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4Eb_VPChbnI",
        "outputId": "b234bfb2-46de-4fa6-dfb0-5a0cdcc7c6df"
      },
      "source": [
        "stae = modelBuilder.build()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=======================================\n",
            "[INFO] Model compilation Done..\n",
            "=======================================\n",
            "\n",
            "Model: \"Spatio-Temporal-AutoEncoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 227, 227, 10, 1)] 0         \n",
            "_________________________________________________________________\n",
            "conv3d_12 (Conv3D)           (None, 55, 55, 10, 128)   15616     \n",
            "_________________________________________________________________\n",
            "conv3d_13 (Conv3D)           (None, 26, 26, 10, 64)    204864    \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_18 (ConvLSTM2D) (None, 26, 26, 10, 64)    295168    \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_19 (ConvLSTM2D) (None, 26, 26, 10, 32)    110720    \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_20 (ConvLSTM2D) (None, 26, 26, 10, 64)    221440    \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_12 (Conv3DT (None, 55, 55, 10, 128)   204928    \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_13 (Conv3DT (None, 227, 227, 10, 1)   15489     \n",
            "=================================================================\n",
            "Total params: 1,068,225\n",
            "Trainable params: 1,068,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6-abVDfiRl3"
      },
      "source": [
        "# Loading our Image Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2jMtwQqhlHh"
      },
      "source": [
        "train_data = np.load('./drive/MyDrive/AnormalyDetectionDataset/training.npy')\r\n",
        "frames = train_data.shape[2]\r\n",
        "frames = frames - frames%10\r\n",
        "\r\n",
        "train_data = train_data[:, :, :frames]\r\n",
        "train_data = train_data.reshape(-1, 227, 227, 10)\r\n",
        "\r\n",
        "train_data = np.expand_dims(train_data, axis = 4)\r\n",
        "target_data = train_data.copy()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IybGl73gjoPI"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnDvqxkejQuN"
      },
      "source": [
        "epochs = 5\r\n",
        "batch_size = 1\r\n",
        "\r\n",
        "if not os.path.exists(\"./drive/MyDrive/AnormalyDetectionDataset/Model\"):\r\n",
        "    os.mkdir(\"./drive/MyDrive/AnormalyDetectionDataset/Model\")\r\n",
        "\r\n",
        "model_save = ModelCheckpoint(\"./drive/MyDrive/AnormalyDetectionDataset/Model/stae.h5\",\r\n",
        "                            monitor = 'mean_squared_error',\r\n",
        "                            save_best_only = True)\r\n",
        "early_stop = EarlyStopping(monitor = 'mean_squared_error',\r\n",
        "                        patience = 3,\r\n",
        "                        mode = 'min',\r\n",
        "                        restore_best_weights = True)\r\n",
        "\r\n",
        "callbacks = [early_stop, model_save]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw07oW2tkq9w",
        "outputId": "6340913e-c89d-449c-c33d-1a5b148dc712"
      },
      "source": [
        "training_history = stae.fit(x = train_data, \r\n",
        "                            y = target_data,\r\n",
        "                            batch_size = batch_size,\r\n",
        "                            epochs = epochs,\r\n",
        "                            callbacks = callbacks)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 45s 301ms/step - loss: 0.2696 - accuracy: 0.5155\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 7s 289ms/step - loss: 0.2068 - accuracy: 0.5450\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 7s 303ms/step - loss: 0.2005 - accuracy: 0.5437\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 7s 292ms/step - loss: 0.2011 - accuracy: 0.5428\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 7s 288ms/step - loss: 0.1971 - accuracy: 0.5472\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `mean_squared_error` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ByhIWB_nSbj"
      },
      "source": [
        "# Saving STAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CohKxto4lQRx"
      },
      "source": [
        "stae.save(\"./drive/MyDrive/AnormalyDetectionDataset/Model/stae.h5\")"
      ],
      "execution_count": 74,
      "outputs": []
    }
  ]
}